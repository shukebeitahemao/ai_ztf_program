





#ä½¿ç”¨llamaindexæ¡†æ¶ï¼Œä½¿ç”¨deepseek clientå’Œchromaå‘é‡æ•°æ®åº“ï¼Œå¯¹txt_split_fileæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶åˆ¶ä½œç´¢å¼•



# åˆ›å»ºå‘é‡å­˜å‚¨
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

# è¯»å–æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶
documents = SimpleDirectoryReader(
    input_dir="fastapi_project/chat/txt_split_file",
    recursive=True
).load_data()

# åˆ›å»ºç´¢å¼•æ—¶ç›´æ¥ä½¿ç”¨ Settings
index = VectorStoreIndex.from_documents(
    documents,
    vector_store=vector_store
)

#ä½¿ç”¨æ–‡æ¡£çº§æ‘˜è¦ç´¢å¼•
from llama_index.core import (
    DocumentSummaryIndex,
    PromptTemplate,
    get_response_synthesizer,
    SimpleDirectoryReader,
)

# è¯»å–åŸå§‹æ–‡æ¡£ï¼ˆç¤ºä¾‹ç”¨ç›®å½•ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä¼ å…¥å·²æ„é€ çš„ Document åˆ—è¡¨ï¼‰
docs = SimpleDirectoryReader("txt_split_file/").load_data()
# âœ… è‡ªå®šä¹‰æ‘˜è¦æ¨¡æ¿ â€”â€” {context_str} ä¼šè¢«æ›¿æ¢æˆå…¨æ–‡
summary_tmpl = PromptTemplate(
    "è¯·ç”¨ 3-4 å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æ¡£ï¼Œå¹¶çªå‡ºä¸ç”¨æˆ·â€˜{topic}â€™ç›¸å…³çš„ä¿¡æ¯ï¼š\n"
    "{context_str}\n"
    "â€”â€” æ‘˜è¦ï¼š"
)
# LlamaIndex â‰¥0.10.x æŠŠ summary_template æ”¶è¿› response_synthesizer
# ä¹Ÿå¿…é¡»åœ¨response_synthesizerä¸­æŸ¥çœ‹æ¨¡æ¿
resp_synth = get_response_synthesizer(
     response_mode="tree_summarize",        # or "tree_summarize"
    summary_template=summary_tmpl
)
# æ„å»º DocumentSummaryIndex
doc_sum_index = DocumentSummaryIndex.from_documents(
    docs,
    response_synthesizer=resp_synth
)
#æŸ¥çœ‹æ¨¡æ¿ï¼Œç¡®è®¤ä½¿ç”¨äº†æˆ‘ä»¬æŒ‡å®šçš„æ¨¡æ¿
# print(resp_synth.get_prompts()["summary_template"].get_template())

#æ‰“å°ç´¢å¼•ä¸­æ¯ç¯‡æ–‡æ¡£çš„æ‘˜è¦
def show_doc_summaries(index: DocumentSummaryIndex):
    """æ‰“å°ç´¢å¼•ä¸­æ¯ç¯‡æ–‡æ¡£çš„æ‘˜è¦"""
    struct = index.index_struct                 # IndexDocumentSummary å¯¹è±¡
    ds = index.docstore

    for doc_id, summary_node_id in struct.doc_id_to_summary_id.items():
        summary_node = ds.get_node(summary_node_id)
        print(f"\n=== æ–‡æ¡£ {doc_id} çš„æ‘˜è¦ ===")
        print(summary_node.get_text())

show_doc_summaries(doc_sum_index)

#ä»ç”¨æˆ·å›ç­”è·å–æ‘˜è¦å†…å®¹
retriever = doc_sum_index.as_retriever(similarity_top_k=5)

# ç”¨æˆ·æé—®
query = "æœ‰å“ªäº›æ–‡æ¡£æ¶‰åŠåœ°æ–¹æ³•é™¢ï¼Ÿ"
# æ‰‹åŠ¨è¿›è¡Œæ£€ç´¢ï¼ˆç»“æœä¸º NodeWithScore å¯¹è±¡ï¼‰
retrieved_nodes = retriever.retrieve(query)
# è¾“å‡ºåŸæ–‡å†…å®¹
for i, node in enumerate(retrieved_nodes):
    print(f"\nğŸ“„ æ–‡æ¡£ç‰‡æ®µ #{i+1}ï¼ˆdoc_id={node.node.ref_doc_id}ï¼‰:")
    print(node.node.text[:500], "...")

    

